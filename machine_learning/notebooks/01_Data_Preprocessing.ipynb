{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing untuk Project SafeFood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library yang dibutuhkan : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library berhasil di import\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Library berhasil di import\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil di load\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/raw/data_donor_recipient_matching.csv\")\n",
    "\n",
    "print(\"Data berhasil di load\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pra-Pemrosesan Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding selesai.\n"
     ]
    }
   ],
   "source": [
    "kolom_kategori = [\n",
    "    'makanan_disumbangkan',\n",
    "    'kondisi_makanan',\n",
    "    'makanan_dibutuhkan',\n",
    "    'kondisi_makanan_diterima',\n",
    "    'status_penerima'\n",
    "]\n",
    "\n",
    "data_encoded = pd.get_dummies(data, columns=kolom_kategori)\n",
    "\n",
    "print(\"One-Hot Encoding selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom latitude dan longitude dihapus.\n",
      "Data selesai dinormalisasi\n"
     ]
    }
   ],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  \n",
    "    return c * r\n",
    "\n",
    "data_encoded['jarak'] = haversine(\n",
    "    data_encoded['lokasi_lat_penyumbang'],\n",
    "    data_encoded['lokasi_lon_penyumbang'],\n",
    "    data_encoded['lokasi_lat_penerima'],\n",
    "    data_encoded['lokasi_lon_penerima']\n",
    ")\n",
    "\n",
    "columns_to_drop = ['lokasi_lat_penyumbang', 'lokasi_lon_penyumbang', 'lokasi_lat_penerima', 'lokasi_lon_penerima']\n",
    "data_encoded.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(\"Kolom latitude dan longitude dihapus.\")\n",
    "\n",
    "columns_to_normalize = ['jumlah_disumbangkan', 'jumlah_dibutuhkan', 'frekuensi_menerima', 'jarak']\n",
    "\n",
    "def min_max_scaling(df, columns):\n",
    "    min_max_values = {}\n",
    "    for col in columns:\n",
    "        col_min = df[col].min()\n",
    "        col_max = df[col].max()\n",
    "        min_max_values[col] = {'min': col_min, 'max': col_max}\n",
    "        \n",
    "        df[col] = (df[col] - col_min) / (col_max - col_min)\n",
    "    return df, min_max_values\n",
    "\n",
    "df_normalized, min_max_dict = min_max_scaling(data_encoded, columns_to_normalize)\n",
    "\n",
    "print(\"Data selesai dinormalisasi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Ubah nilai Boolean ke 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses preprocessing selesai.\n",
      "Data berhasil disimpan ke file CSV.\n"
     ]
    }
   ],
   "source": [
    "boolean_columns = [\n",
    "    'is_halal_donor', 'is_for_child_donor', 'is_for_elderly_donor', 'is_alergan',\n",
    "    'is_halal_receiver', 'is_for_child_receiver', 'is_for_elderly_receiver', 'is_alergan_free',\n",
    "    'makanan_disumbangkan_makanan', 'makanan_disumbangkan_makanan_minuman', \n",
    "    'makanan_disumbangkan_minuman', 'kondisi_makanan_hampir_kadaluarsa', \n",
    "    'kondisi_makanan_layak_konsumsi', 'kondisi_makanan_tidak_layak_konsumsi', \n",
    "    'makanan_dibutuhkan_makanan', 'makanan_dibutuhkan_makanan_minuman', \n",
    "    'makanan_dibutuhkan_minuman', 'kondisi_makanan_diterima_hampir_kadaluarsa', \n",
    "    'kondisi_makanan_diterima_layak_konsumsi', \n",
    "    'kondisi_makanan_diterima_layak_konsumsi_hampir_kadaluarsa', \n",
    "    'kondisi_makanan_diterima_tidak_layak konsumsi', \n",
    "    'status_penerima_mendesak', 'status_penerima_normal', 'status_penerima_tidak mendesak'\n",
    "]\n",
    "\n",
    "df_for_model = df_normalized\n",
    "\n",
    "df_for_model[boolean_columns] = df_normalized[boolean_columns].astype(int)\n",
    "\n",
    "df_for_model.to_csv(\"../data/processed/data_for_model.csv\", index=False)\n",
    "\n",
    "print(\"Proses preprocessing selesai.\")\n",
    "print(\"Data berhasil disimpan ke file CSV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pemisahan Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pemisahan data berdasarkan persentase:`\n",
    "\n",
    "- Training Set: 80% x 10,000 = 8,000 data\n",
    "- Validation Set: 10% x 10,000 = 1,000 data\n",
    "- Test Set: 10% x 10,000 = 1,000 data\n",
    "\n",
    "Training set digunakan untuk melatih model.\n",
    "\n",
    "Validation set digunakan untuk memantau kinerja model selama pelatihan dan mencegah overfitting.\n",
    "\n",
    "Test set digunakan untuk mengukur performa akhir model setelah pelatihan selesai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 8000 data\n",
      "Validation Set: 1000 data\n",
      "Test Set: 1000 data\n",
      "Dataset telah disimpan ke file CSV:\n",
      "- training_set.csv\n",
      "- validation_set.csv\n",
      "- test_set.csv\n",
      "Proses pemisahan dataset selesai.\n"
     ]
    }
   ],
   "source": [
    "train_set, temp_set = train_test_split(df_for_model, test_size=0.2, random_state=42)\n",
    "\n",
    "validation_set, test_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training Set: {train_set.shape[0]} data\")\n",
    "print(f\"Validation Set: {validation_set.shape[0]} data\")\n",
    "print(f\"Test Set: {test_set.shape[0]} data\")\n",
    "\n",
    "train_set.to_csv('../data/processed/training_set.csv', index=False)\n",
    "validation_set.to_csv('../data/processed/validation_set.csv', index=False)\n",
    "test_set.to_csv('../data/processed/test_set.csv', index=False)\n",
    "\n",
    "print(\"Dataset telah disimpan ke file CSV:\")\n",
    "print(\"- training_set.csv\")\n",
    "print(\"- validation_set.csv\")\n",
    "print(\"- test_set.csv\")\n",
    "\n",
    "print(\"Proses pemisahan dataset selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses persiapan data selesai.\n"
     ]
    }
   ],
   "source": [
    "print(\"Proses persiapan data selesai.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
